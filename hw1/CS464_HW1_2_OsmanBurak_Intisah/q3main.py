# -*- coding: utf-8 -*-
"""hmw1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UHCFJcTYvezSEYls7UodUcBSbp_s38Ml

At the beginning I am importing needed libraries  &&
  mounting the drive file into Google Colab
"""

import os
import csv
import copy
import math
import random
import operator
import numpy as np
import pandas as pd
from mpl_toolkits import mplot3d
from mpl_toolkits.mplot3d import Axes3D
from collections import defaultdict

import matplotlib.pyplot as plt
import matplotlib.image as mpimg

root = 'C:/Users/asus/Desktop/'

"""To CHECK whether GPU is working or not !!!
// tf.test.gpu_device_name()

After mounting is done, now I am uploading the needed files.
"""

train = os.path.join(root, 'q2_train_set.txt')
test = os.path.join(root, 'q2_test_set.txt')
gag = os.path.join(root, 'q2_gag_sequence.txt')

print("Reading files...")

with open(train, 'rb') as f:
    train = f.read()

train = train.splitlines()

with open(test, 'rb') as f:
    test = f.read()

test = test.splitlines()

with open(gag, 'rb') as f:
    gag_sequence = f.read()

gag_sequence = np.asarray(gag_sequence.splitlines())

"""Organizing the data

  I have added all the datas to 2D array.
  First 8 columns gives the char and the last gives the **it can be cleaved by HIV-1 PR in the middle or not**
"""

def organize(train):
    test = []
    result = []
    for line in train:
        str_line = str(line, 'utf-8')
        temp = []
        part = []
        for i in str_line:
            if (i != ','):
                part.append(int(i))
            if len(part) == 20:
                temp.append(copy.deepcopy(part))
                part.clear()
        temp.append(part)
        result.append(temp)
    return result


# Organizing train data
train_set = np.asarray(organize(train))
train_label = []
for i in train_set:
    train_label.append(int(i[8][0]))
train_set = np.delete(train_set, 8, 1)

# Organizing test data
test_set = organize(test)
test_label = []
for i in test_set:
    test_label.append(int(i[8][0]))
test_set = np.delete(test_set, 8, 1)

"""Training a **Bernoulli Naive Bayes** model on the training set"""
print()

no_of_train_data = 6062
no_of_0 = 0
no_of_1 = 0

for i in train_label:
    if i == 0:
        no_of_0 += 1
    else:
        no_of_1 += 1

prob_of_y_eq_0 = np.log(no_of_0 / no_of_train_data)
prob_of_y_eq_1 = np.log(no_of_1 / no_of_train_data)

# creating 2d array for how many data for each position each twenty
rows, cols = (8, 20)


# Finding which amino asid is how many times seen in each position (i) corresponding label

def read_until(until):
    when_zero = [[0 for i in range(cols)] for j in range(rows)]
    when_one = [[0 for i in range(cols)] for j in range(rows)]

    # Counting..
    for i in range(0, until):
        for j in range(0, 8):
            part = train_set[i][j]
            for k in range(0, 20):
                if train_label[i] == 0:
                    if part[k] == 1:
                        when_zero[j][k] += 1
                else:
                    if part[k] == 1:
                        when_one[j][k] += 1
    return when_zero, when_one


def find_prob(when_zero, when_one):
    probs_when_zero = [[0 for i in range(cols)] for j in range(rows)]
    probs_when_one = [[0 for i in range(cols)] for j in range(rows)]
    probs_when_zero_itself_zero = [[0 for i in range(cols)] for j in range(rows)]
    probs_when_one_itself_zero = [[0 for i in range(cols)] for j in range(rows)]

    # Finding the probability
    for i in range(0, 8):
        for j in range(0, 20):
            if when_zero[i][j] == 0:
                probs_when_zero[i][j] = -np.inf
            else:
                probs_when_zero[i][j] = np.log(when_zero[i][j] / (no_of_0))

            if when_one[i][j] == 0:
                probs_when_one[i][j] = -np.inf
            else:
                probs_when_one[i][j] = np.log(when_one[i][j] / (no_of_1))

            probs_when_zero_itself_zero[i][j] = np.log(1 - (when_zero[i][j] / (no_of_0)))
            probs_when_one_itself_zero[i][j] = np.log(1 - (when_one[i][j] / (no_of_1)))

    return probs_when_zero, probs_when_one, probs_when_zero_itself_zero, probs_when_one_itself_zero


def find_accuracy(predictions, test_label):
    count = 0
    for i in range(0, 528):
        if predictions[i] == test_label[i]:
            count += 1
    accuracy = (count / 528) * 100
    return accuracy


"""Testing a **Bernoulli Naive Bayes** model on the test set"""


def pred(probs_when_zero, probs_when_one, probs_when_zero_itself_zero, probs_when_one_itself_zero, all_indxs, ran):
    '''
    Getting the probabilities and predicting the labels
    '''
    predictions = ["none"] * ran
    for i in range(0, ran):
        is_zero = 0
        is_one = 0
        for j in range(0, 8):
            ind = all_indxs[i][j]
            for k in range(0, 20):
                if k == ind:
                    is_zero += probs_when_zero[j][k]
                    is_one += probs_when_one[j][k]
                else:
                    is_zero += probs_when_zero_itself_zero[j][k]
                    is_one += probs_when_one_itself_zero[j][k]

        is_zero += prob_of_y_eq_0
        is_one += prob_of_y_eq_1

        if is_zero >= is_one:
            # print(str(is_zero) +  "           "+  str(is_one))
            predictions[i] = 0
        else:
            predictions[i] = 1
    return predictions


# Now I wil try to get which indexes are one for each amino acid sequence
all_indxs = []
for i in range(0, 528):
    check = test_set[i]
    indxs = []
    for every in check:
        for j in every:
            if j == 1:
                indxs.append(every.index(j))
    all_indxs.append(copy.deepcopy(indxs))
    indxs.clear

print("Question 3.1")
print("Calculating..")
# Reading all training data
when_zero, when_one = read_until(6062)
# Finding the corresponding probabilities
probs_when_zero, probs_when_one, probs_when_zero_itself_zero, probs_when_one_itself_zero = find_prob(when_zero,
                                                                                                     when_one)
# According to model testing the test data
predictions = pred(probs_when_zero, probs_when_one, probs_when_zero_itself_zero, probs_when_one_itself_zero, all_indxs,
                   528)


print("The accuracy of The Bernoulli Naive Bayes")
accuracy = find_accuracy(predictions, test_label)
print(accuracy)
print()

"""**Question 2** STARTING HERE : finding the new 8mers talked about and finding the corresponding places in the dictionary given in homework description."""

gag = str(gag_sequence, 'utf-8')
new_seq = []
new_8mers = []
for i in range(0, len(gag)):
    new_seq.append(gag[i])
    if len(new_seq) == 8:
        new_8mers.append(copy.deepcopy(new_seq))
        new_seq.pop(0)

new_8mers = np.asarray(new_8mers)

dic = ['g', 'p', 'a', 'v', 'l', 'i', 'm', 'c', 'f', 'y', 'w', 'h', 'k', 'r', 'q', 'n', 'e', 'd', 's', 't']

find_num = []
for i in range(0, 493):
    check = new_8mers[i]
    indexs = []
    for j in check:
        for find in dic:
            if find == j:
                indexs.append(dic.index(find))
    find_num.append(copy.deepcopy(indexs))
    indexs.clear()

find_num = find_num

"""The corresponding places are found! 
Now we are going to find the probability of can be cleaved or not according to the model.

places_cleave has the indices of the aminoacids where cleavege occurs.
"""

# Doing predictions for the 8mers found according to our model
predictions = pred(probs_when_zero, probs_when_one, probs_when_zero_itself_zero, probs_when_one_itself_zero, find_num,
                   493)

place_of_1s = []
count = 0
for i in predictions:
    if i == 1:
        place_of_1s.append(count)
    count += 1

# There are 22 places where this HIV can cleave which is known in place_of_1s list
places_cleavage = []

for i in place_of_1s:
    place = i + 4
    places_cleavage.append(place)
print("Question 3.2")
print(len(places_cleavage))
print(places_cleavage)
print()
"""#QUESTION 3
I have used a greedy method and find the best for each position
"""

inds = []
for i in probs_when_one:
    max = - np.inf
    for j in i:
        if j >= max:
            max = j
    inds.append(i.index(max))

for_zero = []
for i in probs_when_zero:
    min = np.inf
    for j in i:
        if j <= min:
            min = j
    for_zero.append(i.index(min))

best_first = []
for i in inds:
    best_first.append(dic[i])

worst_zero = []
for i in for_zero:
    worst_zero.append(dic[i])

a = [inds, for_zero]
predictions = pred(probs_when_zero, probs_when_one, probs_when_zero_itself_zero, probs_when_one_itself_zero, a, 2)

print("Question 3.3")
print(predictions)
print(best_first)
print(worst_zero)
print()


"""#QUESTION 4
**First Part**
"""

def division_change(when_zero, when_one, a):
    '''
    Getting the numbers of each aminoacid in particular feature
    And calculating the probability
    '''
    l0 = [[0 for i in range(cols)] for j in range(rows)]
    l1 = [[0 for i in range(cols)] for j in range(rows)]
    l0i0 = [[0 for i in range(cols)] for j in range(rows)]
    l1i0 = [[0 for i in range(cols)] for j in range(rows)]

    for i in range(0, 8):
        for j in range(0, 20):
            if when_zero[i][j] == 0:
                l0[i][j] = -np.inf
            else:
                l0[i][j] = np.log((when_zero[i][j] + a) / ((no_of_0) + (2 * a)))

            if when_one[i][j] == 0:
                l1[i][j] = -np.inf
            else:
                l1[i][j] = np.log((when_one[i][j] + a) / ((no_of_1) + (2 * a)))

            l0i0[i][j] = np.log(((no_of_0 - when_zero[i][j] + a) / ((no_of_0) + (2 * a))))
            l1i0[i][j] = np.log(((no_of_1 - when_one[i][j] + a) / ((no_of_1) + (2 * a))))

    return l0, l1, l0i0, l1i0


alfa = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]

acc_list = []
print("Question 3.4.1")
print("Calculating...")
for i in alfa:
    # Changing the probabilites since each alfa value changes the probabilities for each feature
    a, b, c, d = division_change(when_zero, when_one, i)

    # Doing the prediction for the test data
    predictions = pred(a, b, c, d, all_indxs, 528)

    # Finding the accuracy
    print("The accuracy when alfa = " + str(i))
    accuracy = find_accuracy(predictions, test_label)
    acc_list.append(accuracy)
    print(accuracy)

## PLOTTING
plt.plot(alfa, acc_list, '--go', label='all_data')
leg = plt.legend();
plt.title('Alfa vs Accuracy')
plt.xlabel('Alfa')
plt.ylabel('Test Set Accuracy')
plt.style.use('ggplot')
plt.show()
print()

"""#QUESTION 4
**Second Part**
"""

no_of_0_first_75 = 0
no_of_1_first_75 = 0
for i in test_label[0:75]:
    if i == 0:
        no_of_0_first_75 += 1
    else:
        no_of_1_first_75 += 1


def probs_when_75(when_zero, when_one, a, no_of_0_first_75, no_of_1_first_75):
    '''
    Getting the numbers of each aminoacid in particular feature
    And calculating the probability
    '''
    l0 = [[0 for i in range(cols)] for j in range(rows)]
    l1 = [[0 for i in range(cols)] for j in range(rows)]
    l0i0 = [[0 for i in range(cols)] for j in range(rows)]
    l1i0 = [[0 for i in range(cols)] for j in range(rows)]

    for i in range(0, 8):
        for j in range(0, 20):
            if when_zero[i][j] == 0:
                l0[i][j] = -np.inf
            else:
                l0[i][j] = np.log((when_zero[i][j] + a) / ((no_of_0_first_75) + (2 * a)))

            if when_one[i][j] == 0:
                l1[i][j] = -np.inf
            else:
                l1[i][j] = np.log((when_one[i][j] + a) / ((no_of_1_first_75) + (2 * a)))

            l0i0[i][j] = np.log(((no_of_0_first_75 - when_zero[i][j] + a) / ((no_of_0_first_75) + (2 * a))))
            l1i0[i][j] = np.log(((no_of_1_first_75 - when_one[i][j] + a) / ((no_of_1_first_75) + (2 * a))))

    return l0, l1, l0i0, l1i0


def pred_for_75(l0, l1, l0i0, l1i0, all_indxs, ran):
    '''
    Getting the probabilities and predicting the labels
    '''
    predictions = ["none"] * ran
    for i in range(0, ran):
        is_zero = 0
        is_one = 0
        for j in range(0, 8):
            ind = all_indxs[i][j]
            for k in range(0, 20):
                if k == ind:
                    is_zero += l0[j][k]
                    is_one += l1[j][k]
                else:
                    is_zero += l0i0[j][k]
                    is_one += l1i0[j][k]

        is_zero += no_of_0_first_75 / 75
        is_one += no_of_1_first_75 / 75

        if is_zero >= is_one:
            # print(str(is_zero) +  "           "+  str(is_one))
            predictions[i] = 0
        else:
            predictions[i] = 1
    return predictions


# Reading first 75 lines and finding which indexes are 0 and 1 and in which plce
when_zero, when_one = read_until(75)

result = []
print("Question 3.4.2")
print("Calculating...")
for i in alfa:
    # finding the probabilities when we use 75 training data
    a, b, c, d = probs_when_75(when_zero, when_one, i, no_of_0_first_75, no_of_1_first_75)

    # Predicting the labels with using the 75 training data model
    predictions = pred_for_75(a, b, c, d, all_indxs, 528)


    # Finding the accuracy
    print("The accuracy (when training size is 75) when alfa = " + str(i))
    accuracy = find_accuracy(predictions, test_label)
    result.append(accuracy)
    print(accuracy)

## PLOTTING
plt.plot(alfa, result, '--go', label='first_75')
leg = plt.legend();
plt.title('Alfa vs Accuracy (75 Training Data)')
plt.xlabel('Alfa')
plt.ylabel('Test Set Accuracy')
plt.style.use('ggplot')
plt.show()
print()

# Updating the numbers back to the original!
# Which to be used in the continuos questions!!
when_zero, when_one = read_until(6062)

"""#Question 5
**Starting Here**
"""

# Reading all training data
when_zero, when_one = read_until(6062)
# Findign mutual informations according to the page provided
mutual_info = []
for i in range(0, 160):
    x = int(i / 20)
    y = int(i % 20)
    a = when_one[x][y]
    b = when_zero[x][y]
    c = no_of_1 - a
    d = no_of_0 - b
    n1dot = a + b
    ndot1 = a + c
    n0dot = c + d
    ndot0 = b + d
    n = a + b + c + d

    if (n1dot * ndot1) == 0 or (n0dot * ndot1) == 0 or (n1dot * ndot0) == 0 or (n0dot * ndot0) == 0 or (n * a) == 0 or (
            n * b) == 0 or (n * c) == 0 or (n * d) == 0:
        info = np.inf
    else:
        info = ((a / n) * (np.log2((n * a) / (n1dot * ndot1)))) + ((c / n) * (np.log2((n * c) / (n0dot * ndot1)))) + (
                    (b / n) * (np.log2((n * b) / (n1dot * ndot0)))) + ((d / n) * (np.log2((n * d) / (n0dot * ndot0))))

    mutual_info.append([x, y, info])

# Sorting mutual information values in descending order and also I keep the original indices.
sorted_mutual = sorted(mutual_info, key=lambda x: -x[2])


# helper functions for question 5
def read_only_corresponding_features(features):
    a = [[0 for i in range(cols)] for j in range(rows)]
    b = [[0 for i in range(cols)] for j in range(rows)]

    for i in range(0, 6062):
        sequence = train_set[i]
        for each in features:
            x = int(each[0])
            y = int(each[1])
            # Counting..
            feature = sequence[x][y]
            if train_label[i] == 0:
                if feature == 1:
                    a[x][y] += 1
            else:
                if feature == 1:
                    b[x][y] += 1
    return a, b


def find_prob_question5(when_zero, when_one, features):
    probs_when_zero = [[0 for i in range(cols)] for j in range(rows)]
    probs_when_one = [[0 for i in range(cols)] for j in range(rows)]
    probs_when_zero_itself_zero = [[0 for i in range(cols)] for j in range(rows)]
    probs_when_one_itself_zero = [[0 for i in range(cols)] for j in range(rows)]

    # Finding the probability
    for each in features:
        i = int(each[0])
        j = int(each[1])
        if when_zero[i][j] == 0:
            probs_when_zero[i][j] = -np.inf
        else:
            probs_when_zero[i][j] = np.log(when_zero[i][j] / (no_of_0))

        if when_one[i][j] == 0:
            probs_when_one[i][j] = -np.inf
        else:
            probs_when_one[i][j] = np.log(when_one[i][j] / (no_of_1))

        probs_when_zero_itself_zero[i][j] = np.log(1 - (when_zero[i][j] / (no_of_0)))
        probs_when_one_itself_zero[i][j] = np.log(1 - (when_one[i][j] / (no_of_1)))
    return probs_when_zero, probs_when_one, probs_when_zero_itself_zero, probs_when_one_itself_zero


# Train a model  using all training set instances, but only use first k features
result = []
print("Question 3.5")
print("Calculating...")
for step in range(1, 161):
    features = sorted_mutual[0:step]
    a, b = read_only_corresponding_features(features)
    l0, l1, l0i0, l1i0 = find_prob_question5(a, b, features)

    predictions = pred(l0, l1, l0i0, l1i0, all_indxs, 528)

    # Finding the accuracy

    #print("The accuracy of The Bernoulli Naive Bayes for k = " + str(step) + " calculated...")
    accuracy = find_accuracy(predictions, test_label)
    result.append(accuracy)
    #print(accuracy)

max_accuracy = np.amax(result)
max_index = []
for i in range (len(result)):
    num = result[i]
    if math.isclose(num,max_accuracy, rel_tol=1e-5):
        max_index.append(i+1)

#print(result)
print("Max Accuracy:")
print(max_accuracy)
print("Max Indexes:")
print(max_index)
print()

"""#Question 6
**Starting here**
"""
print("Question 3.6")
print("Calculating...")

# Reading all training data
when_zero, when_one = read_until(6062)
to_use = []
for i in train_set:
    row = []
    for j in i:
        for x in j:
            row.append(x)
    to_use.append(row)
to_use = np.asarray(to_use, dtype='float32')

column_vectors = []
for i in range(0, 160):
    column_vectors.append(to_use[:, i])

x_tre = np.sum(to_use, axis=0)
x_tre_mean = np.divide(x_tre, 6062)

for i in range(0, 160):
    for j in range(0, 6062):
        column_vectors[i][j] = (column_vectors[i][j] - x_tre_mean[i])

cov_mat = np.cov(column_vectors)
e_val, e_vec = np.linalg.eig(cov_mat)

first3_e_val = e_val[0:3]
first3_e_vec = e_vec[0:3]

sum_evals = np.sum(e_val, axis=0)

pves = []
for i in range(0, 3):
    eigen_val = first3_e_val[i]
    eigen_vec = first3_e_vec[i]
    pve = eigen_val / sum_evals
    pves.append(pve)

pves = np.asarray(pves, dtype= 'float64')
print("Proportion of variance explained (PVE): ")
print(pves)

print()
fig = plt.figure()
ax = plt.axes(projection="3d")
x_points = np.dot(to_use, first3_e_vec[0])
x_points = np.asarray(x_points, dtype= 'float32')
y_points = np.dot(to_use, first3_e_vec[1])
y_points = np.asarray(y_points, dtype= 'float32')
z_points = np.dot(to_use, first3_e_vec[2])
z_points = np.asarray(z_points, dtype= 'float32')
ax.scatter3D(x_points, y_points, z_points, c='r');

plt.title('3D Projections of amino acid 8-mers')

plt.show()